
# Copyright (c) 2024 Amphion.
#
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.

# from models.tts.maskgct.maskgct_inference import maskgct_run
# maskgct_run()

import soundfile as sf
import safetensors
from models.tts.maskgct.maskgct_utils import *
from models.load_model import load_model_list, get_device_list
from models.load_model import OBJECT_DIR
import folder_paths

device_list = get_device_list()

CATEGORY_NAME = "MaskGCT"


class load_maskgct_model:
    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "maskgct_model": (["amphion_maskgct",],),
                "device": (list(device_list[0].keys()), {"default": str(device_list[1])}),
            },
            "optional": {
            }
        }
    CATEGORY = CATEGORY_NAME
    RETURN_TYPES = ("maskgct_model",)
    RETURN_NAMES = ("maskgct_model",)
    # OUTPUT_IS_LIST = (True,)
    FUNCTION = "load_maskgct_model"

    def load_maskgct_model(self, maskgct_model, device):
        # build model
        device = device_list[0][device]
        cfg_path = os.path.join(OBJECT_DIR,"models/tts/maskgct/config/maskgct.json")
        cfg = load_config(cfg_path)
        # 1. build semantic model (w2v-bert-2.0)
        # semantic_model, semantic_mean, semantic_std = build_semantic_model(device)
        # 2. build semantic_codec
        semantic_codec = build_semantic_codec(cfg.model.semantic_codec, device)
        # 3. build acoustic codec
        codec_encoder, codec_decoder = build_acoustic_codec(
            cfg.model.acoustic_codec, device
        )
        # 4. build t2s model
        t2s_model = build_t2s_model(cfg.model.t2s_model, device)
        # 5. build s2a model
        s2a_model_1layer = build_s2a_model(
            cfg.model.s2a_model.s2a_1layer, device)
        s2a_model_full = build_s2a_model(cfg.model.s2a_model.s2a_full, device)

        # download checkpoint
        # download semantic codec ckpt
        maskgct_repo_id = "amphion/MaskGCT"
        file_list = [
            "semantic_codec/model.safetensors",
            "acoustic_codec/model.safetensors",
            "acoustic_codec/model_1.safetensors",
            "t2s_model/model.safetensors",
            "s2a_model/s2a_model_1layer/model.safetensors",
            "s2a_model/s2a_model_full/model.safetensors"
        ]
        semantic_code_ckpt, codec_encoder_ckpt, codec_decoder_ckpt, t2s_model_ckpt, s2a_1layer_ckpt, s2a_full_ckpt = load_model_list(
            maskgct_repo_id, file_list=file_list)

        # load semantic codec
        safetensors.torch.load_model(semantic_codec, semantic_code_ckpt)
        # load acoustic codec
        safetensors.torch.load_model(codec_encoder, codec_encoder_ckpt)
        safetensors.torch.load_model(codec_decoder, codec_decoder_ckpt)
        # load t2s model
        safetensors.torch.load_model(t2s_model, t2s_model_ckpt)
        # load s2a model
        safetensors.torch.load_model(s2a_model_1layer, s2a_1layer_ckpt)
        safetensors.torch.load_model(s2a_model_full, s2a_full_ckpt)
        model_list = [
            semantic_codec,
            codec_encoder,
            codec_decoder,
            t2s_model,
            s2a_model_1layer,
            s2a_model_full,
        ]
        return (model_list,)


class load_w2vbert_model:
    DESCRIPTION = """
    
    """

    @classmethod
    def INPUT_TYPES(s):
        return {
            "required": {
                "w2vbert_model": (["w2v-bert-v2.0",],),
                "device": (list(device_list[0].keys()), {"default": str(device_list[1])}),
            },
        }
    CATEGORY = CATEGORY_NAME
    RETURN_TYPES = ("w2vbert_model",)
    RETURN_NAMES = ("w2vbert_model",)
    # OUTPUT_IS_LIST = (True,)
    FUNCTION = "load_w2vbert_model"

    def load_w2vbert_model(self, w2vbert_model, device):
        device = device_list[0][device]
        if w2vbert_model == "w2v-bert-v2.0":
            # 1. build semantic model (w2v-bert-2.0)
            return (build_semantic_model(device),)
        else:
            print("error: please select a valid model! ")
            return (None,)


class maskgct_run:
    DESCRIPTION = """
    
    """

    @classmethod
    def INPUT_TYPES(s):
        wav_path= os.path.join(OBJECT_DIR,"sample/trump_0.wav")
        return {
            "required": {
                "maskgct_model": ("maskgct_model",),
                "w2vbert_model": ("w2vbert_model",),
                "sample_wav_path": ("STRING", {"default": wav_path}),
                "prompt_text": ("STRING", {"default": "We do not break. We never give in. We never back down."}),
                "target_text": ("STRING", {"default": "In this paper, we introduce MaskGCT, a fully non-autoregressive TTS model that eliminates the need for explicit alignment information between text and speech supervision."}),
                "InputLanguage": (["en", "zh", "ja", "fr", "ko", "de",], {"default": "en"}),
                "OutputLanguage": (["en", "zh", "ja", "fr", "ko", "de",], {"default": "en"}),
                "target_len": ("INT", {"default": 18, "min": 1, "max": 999999}),
                "device": (list(device_list[0].keys()), {"default": str(device_list[1])}),
            },
            "optional": {
            }
        }
    CATEGORY = CATEGORY_NAME
    RETURN_TYPES = ("AUTO",)
    RETURN_NAMES = ("AUTO",)
    FUNCTION = "maskgct_run"

    def maskgct_run(self, 
                    maskgct_model, 
                    w2vbert_model, 
                    sample_wav_path, 
                    prompt_text, 
                    target_text, 
                    InputLanguage, 
                    OutputLanguage, 
                    target_len, 
                    device):
        # Specify the target duration (in seconds). If target_len = None, we use a simple rule to predict the target duration.
        device = device_list[0][device]

        maskgct_inference_pipeline = MaskGCT_Inference_Pipeline(
            w2vbert_model[0],
            *maskgct_model,
            w2vbert_model[1],
            w2vbert_model[2],
            device,
        )

        recovered_audio = maskgct_inference_pipeline.maskgct_inference(
            sample_wav_path, prompt_text, target_text, InputLanguage, OutputLanguage, target_len=target_len
        )
        return (recovered_audio,)


class save_audio:
    DESCRIPTION = """
    
    """
    @classmethod
    def INPUT_TYPES(s):
        save_name = os.path.join(folder_paths.output_directory, "maskgct.wav")
        return {
            "required": {
                "audio": ("AUTO",),
                "save_path": ("STRING", {"default": save_name}),
            }
        }
    CATEGORY = CATEGORY_NAME
    RETURN_TYPES = ("STRING",)
    RETURN_NAMES = ("save_path",)
    OUTPUT_NODE = True
    FUNCTION = "save_audio"

    def save_audio(self, audio, save_path):
        sf.write(save_path, audio, 24000)
        return (save_path,)


NODE_CLASS_MAPPINGS = {
    "load_maskgct_model": load_maskgct_model,
    "load_w2vbert_model": load_w2vbert_model,
    "maskgct_run": maskgct_run,
    "save_audio": save_audio,
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "load_maskgct_model": "Load MaskGCT Model",
    "load_w2vbert_model": "Load W2VBert Model",
    "maskgct_run": "MaskGCT Run",
    "save_audio": "Save Audio",
}
